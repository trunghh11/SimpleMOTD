{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af58ba85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In /home/nlplab9/anaconda3/envs/dstc_cyj/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/nlplab9/anaconda3/envs/dstc_cyj/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/nlplab9/anaconda3/envs/dstc_cyj/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In /home/nlplab9/anaconda3/envs/dstc_cyj/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/nlplab9/anaconda3/envs/dstc_cyj/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/nlplab9/anaconda3/envs/dstc_cyj/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/nlplab9/anaconda3/envs/dstc_cyj/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/nlplab9/anaconda3/envs/dstc_cyj/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import cv2\n",
    "import shutil\n",
    "import torch\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import torchvision.transforms as T\n",
    "import seaborn as sns\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "from torch import nn, optim\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm import tqdm\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import PIL.Image as Image\n",
    "\n",
    "\n",
    "def load_json(filename):\n",
    "    with open(filename,mode=\"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_json(data,filename):\n",
    "    with open(filename, mode=\"w\") as f:\n",
    "        json.dump(data,f)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b0fca11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove data\n",
    "# !rm -rf vision_data/color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bcf1f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=1\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "\n",
    "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
    "\n",
    "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f07c1759",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "cwd = Path().resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7a947d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scene_folder = \"simmc2_scene_jsons_dstc10_public\"\n",
    "scene_folder = \"simmc2_scene_jsons_dstc10_teststd\"\n",
    "scenes = sorted(glob(str(scene_folder + \"/*_scene.json\")))\n",
    "bboxes = sorted(glob(str(scene_folder + \"/*_bbox.json\")))\n",
    "\n",
    "image_path1=str(cwd)+  \"/simmc2_scene_images_dstc10_public_part2\"\n",
    "image_path2=str(cwd)+ \"/simmc2_scene_images_dstc10_public_part1\"\n",
    "image_path_test =str(cwd)+ \"/simmc2_scene_images_dstc10_teststd\"\n",
    "image_files1 = [f for f in listdir(image_path1) if isfile(join(image_path1, f))]\n",
    "image_files2 = [f for f in listdir(image_path2) if isfile(join(image_path2, f))]\n",
    "image_files_test = [f for f in listdir(image_path_test) if isfile(join(image_path_test, f))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e2dd079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scenes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ed06b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3f03232",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from meta_converter import MetaConverter\n",
    "mc = MetaConverter(\"./\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb941e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a865fb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(): \n",
    "\n",
    "\n",
    "    # GENERIC VERSION OF GENERATING ORIGINAL DATA\n",
    "    index2data={}\n",
    "    object_dict={}\n",
    "    index=0\n",
    "    scene_folder = \"simmc2_scene_jsons_dstc10_teststd\"\n",
    "    scenes = sorted(glob(str(scene_folder + \"/*_scene.json\")))\n",
    "#     print(len(scenes))\n",
    "    for scene in tqdm(scenes):\n",
    "        if \"wayfair\" in scene:\n",
    "            domain = \"furniture\"\n",
    "        else:\n",
    "            domain = \"fashion\"\n",
    "        scene_data=load_json(scene)\n",
    "        scene_objects = scene_data[\"scenes\"][0][\"objects\"] #object lists\n",
    "\n",
    "        scene_name = scene.replace(\"_scene.json\",\"\").split(\"/\")[-1]\n",
    "        scene_image = scene_name\n",
    "    #     print(image_path1 + \"/\" + scene_image + \".png\")\n",
    "    #     print(scene_image)\n",
    "\n",
    "        if scene_image[0]==\"m\":\n",
    "            scene_image=scene_image[2:]\n",
    "        if scene_image + \".png\" in image_files_test:\n",
    "            im = cv2.imread(image_path_test + \"/\" + scene_image + \".png\")\n",
    "#         if scene_image + \".png\" in image_files1:\n",
    "#             im = cv2.imread(image_path1 + \"/\" + scene_image + \".png\")\n",
    "#         elif scene_image + \".png\" in image_files2:\n",
    "#             im = cv2.imread(image_path2 + \"/\" + scene_image + \".png\")\n",
    "        else:\n",
    "            print(\"there is no image available\")\n",
    "            continue\n",
    "\n",
    "        # got image and scene data\n",
    "        error_flag=False\n",
    "        for obj in scene_objects:\n",
    "#             print(obj)\n",
    "            try:\n",
    "                bbox = obj[\"bbox\"]\n",
    "                x=bbox[0]\n",
    "                y=bbox[1]\n",
    "                h=bbox[2]\n",
    "                w=bbox[3]\n",
    "                if h==0 or w==0:\n",
    "                    raise Exception('bounding box size is zero!')\n",
    "                # error if image has \n",
    "                crop_img = im[y:y+h, x:x+w]\n",
    "                input_img = Image.fromarray(crop_img)\n",
    "                meta_list = mc.convert_image(input_img,domain)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                meta_list = []\n",
    "                pass\n",
    "\n",
    "\n",
    "            if scene_name not in object_dict:\n",
    "                object_dict[scene_name]={}\n",
    "            object_dict[scene_name][obj[\"index\"]]=meta_list\n",
    "\n",
    "\n",
    "\n",
    "    return object_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3da020c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 20/205 [00:08<00:57,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bounding box size is zero!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 42/205 [00:17<01:07,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bounding box size is zero!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 63/205 [00:26<01:05,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bounding box size is zero!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 153/205 [01:18<00:16,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bounding box size is zero!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 155/205 [01:19<00:22,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bounding box size is zero!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 157/205 [01:20<00:19,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bounding box size is zero!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 163/205 [01:23<00:17,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bounding box size is zero!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 205/205 [01:36<00:00,  2.13it/s]\n"
     ]
    }
   ],
   "source": [
    "object_dict = preprocess_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ec4244e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b40cb669",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(\"object_100_threshold.pickle\", 'w') as out:\n",
    "  pickle.dump(object_dict,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8242346",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"object_100_threshold.json\", 'w') as out:\n",
    "  json.dump(object_dict,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34c45a95",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-bae5fabb0278>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'image_dict' is not defined"
     ]
    }
   ],
   "source": [
    "# len(image_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e84aa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# color_dict={}\n",
    "# seen_colors={}\n",
    "# for k,v in image_dict.items():\n",
    "#     if len(v[1][\"color\"].split(\",\"))==1:\n",
    "#         color=v[1][\"color\"]\n",
    "#         im=v[2]\n",
    "#         if color not in seen_colors:\n",
    "#             seen_colors[color]=0\n",
    "#         seen_colors[color]+=1\n",
    "#         color_dict[k]=[color,im]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6656c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# len(color_dict)==32937"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa9c3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5ae9feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build directories for data\n",
    "def build_color_dataset(image_dict):\n",
    "    color_dict={}\n",
    "    seen_colors={}\n",
    "    for k,v in image_dict.items():\n",
    "        if len(v[1][\"color\"].split(\",\"))==1:\n",
    "            color=v[1][\"color\"]\n",
    "            im=v[2]\n",
    "            if color not in seen_colors:\n",
    "                seen_colors[color]=0\n",
    "            seen_colors[color]+=1\n",
    "            color_dict[k]=[color,im]   \n",
    "    \n",
    "    type_set=list(seen_colors.keys())\n",
    "    \n",
    "    DATA_DIR = Path(f'vision_data/color/color_data')\n",
    "    ORG_DATA_DIR = Path(f'vision_data/color/original_color_data')\n",
    "    DATASETS=[\"train\",\"val\"]\n",
    "    for ds in DATASETS:\n",
    "        for cls in type_set:\n",
    "            (DATA_DIR / ds / cls).mkdir(parents=True, exist_ok=True)\n",
    "    for cls in type_set:\n",
    "        (ORG_DATA_DIR / cls).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        \n",
    "    # save photo in the correct folder\n",
    "    for key,value in color_dict.items():\n",
    "        cv2.imwrite(str(ORG_DATA_DIR / value[0] / (key+\".jpeg\")), value[1])\n",
    "            \n",
    "    for i, ty in enumerate(type_set):\n",
    "        image_paths = np.array(glob(f'{ORG_DATA_DIR}/{ty}/*.jpeg'))\n",
    "        class_name = ty\n",
    "#             print(f'{class_name}: {len(image_paths)}')\n",
    "        np.random.shuffle(image_paths)\n",
    "\n",
    "        ds_split = np.split(\n",
    "        image_paths, \n",
    "        #     indices_or_sections=[int(.8*len(image_paths)), int(.9*len(image_paths))]\n",
    "        indices_or_sections=[int(.9*len(image_paths))]\n",
    "\n",
    "        )\n",
    "\n",
    "        dataset_data = zip(DATASETS, ds_split)\n",
    "\n",
    "        for ds, images in dataset_data:\n",
    "            for img_path in images:\n",
    "              shutil.copy(img_path, f'{DATA_DIR}/{ds}/{class_name}/')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ce21ce9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-c2c984f8e507>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbuild_color_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'image_dict' is not defined"
     ]
    }
   ],
   "source": [
    "build_color_dataset(image_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e8094c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "filename=\"simmc2_dials_dstc10_train.json\"\n",
    "with open(filename,\"r\") as f:\n",
    "    train_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc99bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 턴마다 최대 등장하는 오브젝트 개수.\n",
    "numset=set()\n",
    "for d in train_data[\"dialogue_data\"]:\n",
    "#     print(d.keys())\n",
    "    for t in d[\"dialogue\"]:\n",
    "        numset.add(len(t[\"system_transcript_annotated\"][\"act_attributes\"][\"objects\"]))\n",
    "numset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d8e0b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c996510c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dstc_cyj",
   "language": "python",
   "name": "dstc_cyj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
